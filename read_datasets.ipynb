{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7685587d-45a9-40bd-bcbb-759997d640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import ffmpeg\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e81a0d-243c-401f-8e48-f26f017f8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abd268",
   "metadata": {},
   "source": [
    "## load data from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de55c50c-9f72-4ada-9198-5fa9dbf4b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(basedir, factor=None, width=None, height=None, split='train'):\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    vid = imageio.get_reader(basedir +'/cam00.mp4',  'ffmpeg')\n",
    "    img0 = vid.get_data(0)\n",
    "    sh = img0.shape\n",
    "    r_w, r_h = sh[1], sh[0]\n",
    "    r_w, r_h = r_w / factor, r_h / factor\n",
    "    print(\"poses size:\", poses.shape[-1])\n",
    "    print(\"original image shape:\", (sh[0], sh[1]))\n",
    "    print(\"dst image shape:\", (r_w, r_h))\n",
    "\n",
    "    images = []\n",
    "    timestamps = []\n",
    "    video_list = glob.glob(os.path.join(basedir, '*.mp4'))\n",
    "    print(\"lodading video:\")\n",
    "    for video in tqdm.tqdm(video_list):\n",
    "        if 'cam00.mp4' in video and split == 'train':\n",
    "            continue\n",
    "\n",
    "        if 'cam00.mp4' not in video and split == 'test':\n",
    "            continue\n",
    "\n",
    "        vid = imageio.get_reader(video,  'ffmpeg')\n",
    "        for i, im in enumerate(vid):\n",
    "            im = Image.fromarray(im).resize((int(r_w), int(r_h)))\n",
    "            images.append(im)\n",
    "            timestamps.append(i)\n",
    "    \n",
    "    factor = 1\n",
    "    \n",
    "    poses[:2, 4, :] = np.array(sh[:2]).reshape([2, 1])\n",
    "    poses[2, 4, :] = poses[2, 4, :] * 1./factor\n",
    "\n",
    "    poses = poses.transpose([2,0,1])\n",
    "    bds = bds.transpose([1,0])\n",
    "    \n",
    "    return poses, bds, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb6bad-6416-4f26-96c6-157fa30c95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir\n",
    "factor=1\n",
    "width=None\n",
    "height=None\n",
    "split='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a91975-ede9-4a40-ae4d-efaa2b7f9cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.57905126, -0.77732271, -0.54637897,  2.6524117 ,  0.65463197,\n",
       "        0.32031655])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([-1.2895256280899048, -0.38866135478019714, -0.2731894850730896, 1.326205849647522, 0.3273159861564636, 0.16015827655792236]) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8922fe",
   "metadata": {},
   "source": [
    "## load json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d3e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data_from_json(basedir, factor=1, width=None, height=None, split='train'):\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    json_file = os.path.join(basedir, f'images_x{factor}_list.json')\n",
    "    with open(json_file) as jf:\n",
    "        json_data = json.load(jf)\n",
    "    \n",
    "    r_w = json_data['videos'][0]['images'][0]['weight']\n",
    "    r_h = json_data['videos'][0]['images'][0]['height']\n",
    "\n",
    "    video_list = json_data['videos']\n",
    "    scene = json_data['scene']\n",
    "    \n",
    "    poses[:2, 4, :] = np.array([r_h, r_w]).reshape([2, 1])\n",
    "\n",
    "    poses = poses.transpose([2,0,1])\n",
    "    bds = bds.transpose([1,0])\n",
    "\n",
    "    images = []\n",
    "    timestamps = []\n",
    "    poses_list = []\n",
    "    bds_list = []\n",
    "    print(\"lodading video:\")\n",
    "    with tqdm(position=0) as progress:\n",
    "        for i, video in enumerate(video_list):\n",
    "            v_name = video['video_name']\n",
    "\n",
    "            if 'cam00' in v_name and split == 'train':\n",
    "                continue\n",
    "\n",
    "            if 'cam00' not in v_name and split == 'test':\n",
    "                continue\n",
    "\n",
    "            pose = poses[i]\n",
    "            bd = bds[i]\n",
    "\n",
    "            vids = video['images']\n",
    "            sizeofimage = len(vids)-1 # 0~n-1\n",
    "            progress.set_description_str(f'{scene}-{v_name}')\n",
    "            progress.reset(total=len(vids))\n",
    "            for im in vids:\n",
    "                progress.update()\n",
    "                img = Image.open(im['path'])\n",
    "                idx = im['idx']\n",
    "                images.append(np.array(img))\n",
    "                timestamps.append(idx/sizeofimage)\n",
    "                poses_list.append(pose)\n",
    "                bds_list.append(bd)\n",
    "            progress.refresh()\n",
    "        \n",
    "    return images, poses_list, timestamps, bds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c2994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lodading video:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coffee_martini-cam20: 100%|██████████| 300/300 [00:02<00:00, 128.11it/s]\n"
     ]
    }
   ],
   "source": [
    "images, poses, timestamps, bds = _load_data_from_json(data_path, factor=4, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b408647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.datasets.dnerf_3d_video import SubjectLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96654671-0882-489b-86fd-0696a85896d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lodading video:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coffee_martini-cam20: 100%|██████████| 300/300 [00:02<00:00, 129.27it/s]\n"
     ]
    }
   ],
   "source": [
    "data_root_fp = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets'\n",
    "train_dataset_kwargs = {\"color_bkgd_aug\": \"random\", \"factor\": 4}\n",
    "train_dataset = SubjectLoader(\n",
    "    subject_id='coffee_martini',\n",
    "    root_fp=data_root_fp,\n",
    "    split='train',\n",
    "    num_rays=8192,\n",
    "    **train_dataset_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761ede56-cd9f-4608-bd45-95d8df3ea1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=16,\n",
    "    persistent_workers=True,\n",
    "    batch_size=None,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b981c3-fc51-4a5e-b495-69b0ad0e75af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5158596-9510-47aa-a581-de922c8ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1624b99d-8c74-4434-97b7-3052c5d42277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixels', 'rays', 'color_bkgd', 'timestamps', 'idx'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0d7e4-633a-40e0-8611-7fbb1b331a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['idx'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d64cb",
   "metadata": {},
   "source": [
    "## Covert all video to images using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d70587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam14.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam00.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:30<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam08.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:25<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam11.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:28<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam07.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam18.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:06<01:22,  3.37it/s]"
     ]
    }
   ],
   "source": [
    "data_path_root = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/'\n",
    "scenes = ['coffee_martini', 'cook_spinach', 'cut_roasted_beef', 'flame_salmon_1', 'flame_steak', 'sear_steak']\n",
    "ori_res = (2028, 2704)\n",
    "dst_res = (int(2704/2), int(2028/2))\n",
    "\n",
    "def exc_fn(video_list):\n",
    "    for video_path in video_list:\n",
    "        print(\"start processing video:\", video_path)\n",
    "        out, _ = (\n",
    "            ffmpeg\n",
    "            .input(video_path)\n",
    "            .output('pipe:', format='rawvideo', pix_fmt='rgb24', loglevel=\"quiet\")\n",
    "            .global_args('-hide_banner')\n",
    "            .run(capture_stdout=True)\n",
    "        )\n",
    "\n",
    "        video = (\n",
    "            np\n",
    "            .frombuffer(out, np.uint8)\n",
    "            .reshape([-1, 2028, 2704, 3])\n",
    "        )\n",
    "\n",
    "        basename = os.path.basename(video_path).split('.')[0]\n",
    "        root = os.path.join(data_path, f\"images/{basename}\")\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        print(\"start saving images\")\n",
    "        for idx in tqdm.tqdm(range(video.shape[0])):\n",
    "            img0 = Image.fromarray(video[idx]).resize(dst_res)\n",
    "            img0.save(os.path.join(data_path, root, f'{idx}.png'))\n",
    "\n",
    "        del out\n",
    "        del video\n",
    "\n",
    "p_list = []\n",
    "for scene in scenes:\n",
    "    data_path = os.path.join(data_path_root, scene)\n",
    "    video_list = glob.glob(os.path.join(data_path, '*.mp4'))\n",
    "    # exc_fn(video_list)\n",
    "    p = Process(target=exc_fn, args=(video_list,))\n",
    "    p_list.append(p)\n",
    "    p.start()\n",
    "\n",
    "for p in p_list:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b02f39-3d1f-4497-bb06-c577d00348c6",
   "metadata": {},
   "source": [
    "## HyberNeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c885909-f134-470c-b906-91cf2a52a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.datasets.hypernerf import Load_hyper_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2986f022-70c5-4c26-8c62-29480bd7c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/loyot/workspace/Datasets/NeRF/HyberNeRF/misc_espresso/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58bb28d9-b976-48fa-aaf8-a8456ab2e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f36c15eb-8cbc-486c-82fb-8b73f25f92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = glob.glob(\"/home/loyot/workspace/Datasets/NeRF/HyberNeRF/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc66586b-4d56-429a-8152-998cee600b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [da.split('/')[-1] for da in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14a107c4-0487-4810-813b-c8577ad88b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interp_aleks-teapot',\n",
       " 'interp_chickchicken',\n",
       " 'interp_cut-lemon',\n",
       " 'interp_hand',\n",
       " 'interp_slice-banana',\n",
       " 'interp_torchocolate',\n",
       " 'misc_americano',\n",
       " 'misc_cross-hands',\n",
       " 'misc_espresso',\n",
       " 'misc_keyboard',\n",
       " 'misc_oven-mitts',\n",
       " 'misc_split-cookie',\n",
       " 'misc_tamping',\n",
       " 'vrig_3dprinter',\n",
       " 'vrig_broom',\n",
       " 'vrig_chicken',\n",
       " 'vrig_peel-banana',\n",
       " 'zip_files']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8a4d0f-519b-4e04-9225-480c9209fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.i_train [  0   4   8  12  16  20  24  28  32  36  40  44  48  52  56  60  64  68\n",
      "  72  76  80  84  88  92  96 100 104 108 112 116 120 124 128 132 136 140\n",
      " 144 148 152 156 160 164 168 172 176 180 184 188 192 196 200 204 208 212\n",
      " 216 220 224 228 232 236 240 244 248 252 256 260 264 268 272 276 280 284\n",
      " 288 292 296 300 304 308 312 316 320 324 328 332 336 340 344 348 352 356\n",
      " 360 364 368 372 376 380 384 388 392 396 400 404 408 412 416 420 424 428\n",
      " 432 436 440 444 448 452 456 460 464 468 472 476 480 484 488 492 496 500\n",
      " 504 508 512 516 520 524 528 532 536 540 544 548 552 556 560 564 568 572\n",
      " 576 580 584 588 592 596 600 604 608 612 616 620 624 628 632 636 640 644\n",
      " 648 652 656 660 664 668 672 676 680 684 688 692 696 700 704 708 712 716\n",
      " 720 724 728 732 736 740 744 748 752 756 760 764 768 772 776]\n",
      "self.i_test [  2   6  10  14  18  22  26  30  34  38  42  46  50  54  58  62  66  70\n",
      "  74  78  82  86  90  94  98 102 106 110 114 118 122 126 130 134 138 142\n",
      " 146 150 154 158 162 166 170 174 178 182 186 190 194 198 202 206 210 214\n",
      " 218 222 226 230 234 238 242 246 250 254 258 262 266 270 274 278 282 286\n",
      " 290 294 298 302 306 310 314 318 322 326 330 334 338 342 346 350 354 358\n",
      " 362 366 370 374 378 382 386 390 394 398 402 406 410 414 418 422 426 430\n",
      " 434 438 442 446 450 454 458 462 466 470 474 478 482 486 490 494 498 502\n",
      " 506 510 514 518 522 526 530 534 538 542 546 550 554 558 562 566 570 574\n",
      " 578 582 586 590 594 598 602 606 610 614 618 622 626 630 634 638 642 646\n",
      " 650 654 658 662 666 670 674 678 682 686 690 694 698 702 706 710 714 718\n",
      " 722 726 730 734 738 742 746 750 754 758 762 766 770 774]\n",
      "total 777 images  use cam = False use bg_point= False\n"
     ]
    }
   ],
   "source": [
    "hyper_data = Load_hyper_data(datadir=root+'espresso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa9d234-40bf-4f2b-af99-6ea2271e56c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9971445 , -0.07056575,  0.02689415],\n",
       "       [ 0.07406207,  0.9833857 , -0.16573292],\n",
       "       [-0.01475226,  0.16725151,  0.9858039 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([hyper_data.all_cam_params[0].orientation, hyper_data.all_cam_params[0].position[:, None]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85ba1ca-3cc5-41b3-8c58-6a7d2c65d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00865268, -0.00921293, -0.70470877])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.all_cam_params[0].position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a030efbe-e561-4f55-999e-c6ffefd2cd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99714452, -0.07056575,  0.02689415,  0.00865268],\n",
       "       [ 0.07406207,  0.98338568, -0.16573292, -0.00921293],\n",
       "       [-0.01475226,  0.16725151,  0.9858039 , -0.70470877]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([hyper_data.all_cam_params[0].orientation, hyper_data.all_cam_params[0].position[:, None]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e459337-48b8-4a36-8b9e-3d1a3e7153dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhyper_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_cam_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhyper_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi_test\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "hyper_data.all_cam_params[hyper_data.i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a4bce-f62e-46c2-a01f-19c7357365fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hyper_data.i_test:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17f3f69e-6c6e-4d3d-a29e-c03e0e9e2963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([298.98813, 467.02313], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.all_cam_params[0].principal_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1db5d20-7277-4136-8a73-d5a206e37587",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, k2, k3 = hyper_data.all_cam_params[13].radial_distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0fc6f1a-a7ac-42ff-81ec-c50ee11a681d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08613597"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0458d4c8-fc53-4f78-90ef-fb495e6828c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.val_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed239cc1-416e-4ed2-87db-3fde4a742f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nerfacc]",
   "language": "python",
   "name": "conda-env-nerfacc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdc5c2d0e21a510627c7c0e521ac3deb474e2ecde23607639b19b4bb9e82177e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
