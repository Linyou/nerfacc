{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7685587d-45a9-40bd-bcbb-759997d640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import ffmpeg\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e81a0d-243c-401f-8e48-f26f017f8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abd268",
   "metadata": {},
   "source": [
    "## load data from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de55c50c-9f72-4ada-9198-5fa9dbf4b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(basedir, factor=None, width=None, height=None, split='train'):\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    vid = imageio.get_reader(basedir +'/cam00.mp4',  'ffmpeg')\n",
    "    img0 = vid.get_data(0)\n",
    "    sh = img0.shape\n",
    "    r_w, r_h = sh[1], sh[0]\n",
    "    r_w, r_h = r_w / factor, r_h / factor\n",
    "    print(\"poses size:\", poses.shape[-1])\n",
    "    print(\"original image shape:\", (sh[0], sh[1]))\n",
    "    print(\"dst image shape:\", (r_w, r_h))\n",
    "\n",
    "    images = []\n",
    "    timestamps = []\n",
    "    video_list = glob.glob(os.path.join(basedir, '*.mp4'))\n",
    "    print(\"lodading video:\")\n",
    "    for video in tqdm.tqdm(video_list):\n",
    "        if 'cam00.mp4' in video and split == 'train':\n",
    "            continue\n",
    "\n",
    "        if 'cam00.mp4' not in video and split == 'test':\n",
    "            continue\n",
    "\n",
    "        vid = imageio.get_reader(video,  'ffmpeg')\n",
    "        for i, im in enumerate(vid):\n",
    "            im = Image.fromarray(im).resize((int(r_w), int(r_h)))\n",
    "            images.append(im)\n",
    "            timestamps.append(i)\n",
    "    \n",
    "    factor = 1\n",
    "    \n",
    "    poses[:2, 4, :] = np.array(sh[:2]).reshape([2, 1])\n",
    "    poses[2, 4, :] = poses[2, 4, :] * 1./factor\n",
    "\n",
    "    poses = poses.transpose([2,0,1])\n",
    "    bds = bds.transpose([1,0])\n",
    "    \n",
    "    return poses, bds, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb6bad-6416-4f26-96c6-157fa30c95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir\n",
    "factor=1\n",
    "width=None\n",
    "height=None\n",
    "split='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a91975-ede9-4a40-ae4d-efaa2b7f9cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.57905126, -0.77732271, -0.54637897,  2.6524117 ,  0.65463197,\n",
       "        0.32031655])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([-1.2895256280899048, -0.38866135478019714, -0.2731894850730896, 1.326205849647522, 0.3273159861564636, 0.16015827655792236]) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8922fe",
   "metadata": {},
   "source": [
    "## load json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d3e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data_from_json(basedir, factor=1, width=None, height=None, split='train'):\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    json_file = os.path.join(basedir, f'images_x{factor}_list.json')\n",
    "    with open(json_file) as jf:\n",
    "        json_data = json.load(jf)\n",
    "    \n",
    "    r_w = json_data['videos'][0]['images'][0]['weight']\n",
    "    r_h = json_data['videos'][0]['images'][0]['height']\n",
    "\n",
    "    video_list = json_data['videos']\n",
    "    scene = json_data['scene']\n",
    "    \n",
    "    poses[:2, 4, :] = np.array([r_h, r_w]).reshape([2, 1])\n",
    "\n",
    "    poses = poses.transpose([2,0,1])\n",
    "    bds = bds.transpose([1,0])\n",
    "\n",
    "    images = []\n",
    "    timestamps = []\n",
    "    poses_list = []\n",
    "    bds_list = []\n",
    "    print(\"lodading video:\")\n",
    "    with tqdm(position=0) as progress:\n",
    "        for i, video in enumerate(video_list):\n",
    "            v_name = video['video_name']\n",
    "\n",
    "            if 'cam00' in v_name and split == 'train':\n",
    "                continue\n",
    "\n",
    "            if 'cam00' not in v_name and split == 'test':\n",
    "                continue\n",
    "\n",
    "            pose = poses[i]\n",
    "            bd = bds[i]\n",
    "\n",
    "            vids = video['images']\n",
    "            sizeofimage = len(vids)-1 # 0~n-1\n",
    "            progress.set_description_str(f'{scene}-{v_name}')\n",
    "            progress.reset(total=len(vids))\n",
    "            for im in vids:\n",
    "                progress.update()\n",
    "                img = Image.open(im['path'])\n",
    "                idx = im['idx']\n",
    "                images.append(np.array(img))\n",
    "                timestamps.append(idx/sizeofimage)\n",
    "                poses_list.append(pose)\n",
    "                bds_list.append(bd)\n",
    "            progress.refresh()\n",
    "        \n",
    "    return images, poses_list, timestamps, bds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c2994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lodading video:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coffee_martini-cam20: 100%|██████████| 300/300 [00:02<00:00, 128.11it/s]\n"
     ]
    }
   ],
   "source": [
    "images, poses, timestamps, bds = _load_data_from_json(data_path, factor=4, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b408647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.datasets.dnerf_3d_video import SubjectLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96654671-0882-489b-86fd-0696a85896d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lodading video:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coffee_martini-cam20: 100%|██████████| 300/300 [00:02<00:00, 129.27it/s]\n"
     ]
    }
   ],
   "source": [
    "data_root_fp = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets'\n",
    "train_dataset_kwargs = {\"color_bkgd_aug\": \"random\", \"factor\": 4}\n",
    "train_dataset = SubjectLoader(\n",
    "    subject_id='coffee_martini',\n",
    "    root_fp=data_root_fp,\n",
    "    split='train',\n",
    "    num_rays=8192,\n",
    "    **train_dataset_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761ede56-cd9f-4608-bd45-95d8df3ea1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=16,\n",
    "    persistent_workers=True,\n",
    "    batch_size=None,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b981c3-fc51-4a5e-b495-69b0ad0e75af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5158596-9510-47aa-a581-de922c8ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1624b99d-8c74-4434-97b7-3052c5d42277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixels', 'rays', 'color_bkgd', 'timestamps', 'idx'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0d7e4-633a-40e0-8611-7fbb1b331a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['idx'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d64cb",
   "metadata": {},
   "source": [
    "## Covert all video to images using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d70587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam14.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam00.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:30<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam08.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:25<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam11.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:28<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam07.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing video: /home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini/cam18.mp4\n",
      "start saving images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:06<01:22,  3.37it/s]"
     ]
    }
   ],
   "source": [
    "data_path_root = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/'\n",
    "scenes = ['coffee_martini', 'cook_spinach', 'cut_roasted_beef', 'flame_salmon_1', 'flame_steak', 'sear_steak']\n",
    "ori_res = (2028, 2704)\n",
    "dst_res = (int(2704/2), int(2028/2))\n",
    "\n",
    "def exc_fn(video_list):\n",
    "    for video_path in video_list:\n",
    "        print(\"start processing video:\", video_path)\n",
    "        out, _ = (\n",
    "            ffmpeg\n",
    "            .input(video_path)\n",
    "            .output('pipe:', format='rawvideo', pix_fmt='rgb24', loglevel=\"quiet\")\n",
    "            .global_args('-hide_banner')\n",
    "            .run(capture_stdout=True)\n",
    "        )\n",
    "\n",
    "        video = (\n",
    "            np\n",
    "            .frombuffer(out, np.uint8)\n",
    "            .reshape([-1, 2028, 2704, 3])\n",
    "        )\n",
    "\n",
    "        basename = os.path.basename(video_path).split('.')[0]\n",
    "        root = os.path.join(data_path, f\"images/{basename}\")\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        print(\"start saving images\")\n",
    "        for idx in tqdm.tqdm(range(video.shape[0])):\n",
    "            img0 = Image.fromarray(video[idx]).resize(dst_res)\n",
    "            img0.save(os.path.join(data_path, root, f'{idx}.png'))\n",
    "\n",
    "        del out\n",
    "        del video\n",
    "\n",
    "p_list = []\n",
    "for scene in scenes:\n",
    "    data_path = os.path.join(data_path_root, scene)\n",
    "    video_list = glob.glob(os.path.join(data_path, '*.mp4'))\n",
    "    # exc_fn(video_list)\n",
    "    p = Process(target=exc_fn, args=(video_list,))\n",
    "    p_list.append(p)\n",
    "    p.start()\n",
    "\n",
    "for p in p_list:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa7731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nerfacc]",
   "language": "python",
   "name": "conda-env-nerfacc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdc5c2d0e21a510627c7c0e521ac3deb474e2ecde23607639b19b4bb9e82177e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
