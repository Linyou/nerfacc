{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7685587d-45a9-40bd-bcbb-759997d640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import ffmpeg\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8045710c-fbf5-4025-94c3-b8a2c3f06b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754b4010-c386-42f5-9664-d7072a16cbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c5ccab-5ba5-4c33-9550-64c1179b6fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-99614720"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20000*8192  - 263454720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe81b5a-9ef5-4be0-9c32-22c3c911cd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e9f414-3a0a-4a54-971d-5b33bb7c7d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263454720"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "536*960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6e81a0d-243c-401f-8e48-f26f017f8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/coffee_martini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abd268",
   "metadata": {},
   "source": [
    "## load data from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de55c50c-9f72-4ada-9198-5fa9dbf4b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(basedir, factor=None, width=None, height=None, split='train'):\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    vid = imageio.get_reader(basedir +'/cam00.mp4',  'ffmpeg')\n",
    "    img0 = vid.get_data(0)\n",
    "    sh = img0.shape\n",
    "    r_w, r_h = sh[1], sh[0]\n",
    "    r_w, r_h = r_w / factor, r_h / factor\n",
    "    print(\"poses size:\", poses.shape[-1])\n",
    "    print(\"original image shape:\", (sh[0], sh[1]))\n",
    "    print(\"dst image shape:\", (r_w, r_h))\n",
    "\n",
    "    images = []\n",
    "    timestamps = []\n",
    "    video_list = glob.glob(os.path.join(basedir, '*.mp4'))\n",
    "    print(\"lodading video:\")\n",
    "    for video in tqdm.tqdm(video_list):\n",
    "        if 'cam00.mp4' in video and split == 'train':\n",
    "            continue\n",
    "\n",
    "        if 'cam00.mp4' not in video and split == 'test':\n",
    "            continue\n",
    "\n",
    "        vid = imageio.get_reader(video,  'ffmpeg')\n",
    "        for i, im in enumerate(vid):\n",
    "            im = Image.fromarray(im).resize((int(r_w), int(r_h)))\n",
    "            images.append(im)\n",
    "            timestamps.append(i)\n",
    "    \n",
    "    factor = 1\n",
    "    \n",
    "    poses[:2, 4, :] = np.array(sh[:2]).reshape([2, 1])\n",
    "    poses[2, 4, :] = poses[2, 4, :] * 1./factor\n",
    "\n",
    "    poses = poses.transpose([2,0,1])\n",
    "    bds = bds.transpose([1,0])\n",
    "    \n",
    "    return poses, bds, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb6bad-6416-4f26-96c6-157fa30c95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir\n",
    "factor=1\n",
    "width=None\n",
    "height=None\n",
    "split='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a91975-ede9-4a40-ae4d-efaa2b7f9cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.57905126, -0.77732271, -0.54637897,  2.6524117 ,  0.65463197,\n",
       "        0.32031655])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([-1.2895256280899048, -0.38866135478019714, -0.2731894850730896, 1.326205849647522, 0.3273159861564636, 0.16015827655792236]) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8922fe",
   "metadata": {},
   "source": [
    "## load json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d3e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data_from_json(basedir, factor=1, width=None, height=None, split='train'):\n",
    "    \n",
    "    poses_arr = np.load(os.path.join(basedir, 'poses_bounds.npy'))\n",
    "    poses = poses_arr[:, :-2].reshape([-1, 3, 5]).transpose([1,2,0])\n",
    "    bds = poses_arr[:, -2:].transpose([1,0])\n",
    "    \n",
    "    json_file = os.path.join(basedir, f'images_x{factor}_list.json')\n",
    "    with open(json_file) as jf:\n",
    "        json_data = json.load(jf)\n",
    "    \n",
    "    r_w = json_data['videos'][0]['images'][0]['weight']\n",
    "    r_h = json_data['videos'][0]['images'][0]['height']\n",
    "\n",
    "    video_list = json_data['videos']\n",
    "    scene = json_data['scene']\n",
    "    \n",
    "    poses[:2, 4, :] = np.array([r_h, r_w]).reshape([2, 1])\n",
    "\n",
    "    poses = poses.transpose([2,0,1])\n",
    "    bds = bds.transpose([1,0])\n",
    "\n",
    "    images = []\n",
    "    timestamps = []\n",
    "    poses_list = []\n",
    "    bds_list = []\n",
    "    print(\"lodading video:\")\n",
    "    with tqdm(position=0) as progress:\n",
    "        for i, video in enumerate(video_list):\n",
    "            v_name = video['video_name']\n",
    "\n",
    "            if 'cam00' in v_name and split == 'train':\n",
    "                continue\n",
    "\n",
    "            if 'cam00' not in v_name and split == 'test':\n",
    "                continue\n",
    "\n",
    "            pose = poses[i]\n",
    "            bd = bds[i]\n",
    "\n",
    "            vids = video['images']\n",
    "            sizeofimage = len(vids)-1 # 0~n-1\n",
    "            progress.set_description_str(f'{scene}-{v_name}')\n",
    "            progress.reset(total=len(vids))\n",
    "            for im in vids:\n",
    "                progress.update()\n",
    "                img = Image.open(im['path'])\n",
    "                idx = im['idx']\n",
    "                images.append(np.array(img))\n",
    "                timestamps.append(idx/sizeofimage)\n",
    "                poses_list.append(pose)\n",
    "                bds_list.append(bd)\n",
    "            progress.refresh()\n",
    "        \n",
    "    return images, poses_list, timestamps, bds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c2994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lodading video:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coffee_martini-cam20: 100%|██████████| 300/300 [00:02<00:00, 128.11it/s]\n"
     ]
    }
   ],
   "source": [
    "images, poses, timestamps, bds = _load_data_from_json(data_path, factor=4, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b408647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.datasets.dnerf_3d_video import SubjectLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96654671-0882-489b-86fd-0696a85896d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lodading video:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "coffee_martini-cam20: 100%|██████████| 300/300 [00:02<00:00, 129.27it/s]\n"
     ]
    }
   ],
   "source": [
    "data_root_fp = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets'\n",
    "train_dataset_kwargs = {\"color_bkgd_aug\": \"random\", \"factor\": 4}\n",
    "train_dataset = SubjectLoader(\n",
    "    subject_id='coffee_martini',\n",
    "    root_fp=data_root_fp,\n",
    "    split='train',\n",
    "    num_rays=8192,\n",
    "    **train_dataset_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "761ede56-cd9f-4608-bd45-95d8df3ea1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=16,\n",
    "    persistent_workers=True,\n",
    "    batch_size=None,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b981c3-fc51-4a5e-b495-69b0ad0e75af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5158596-9510-47aa-a581-de922c8ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1624b99d-8c74-4434-97b7-3052c5d42277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixels', 'rays', 'color_bkgd', 'timestamps', 'idx'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0d7e4-633a-40e0-8611-7fbb1b331a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['idx'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d64cb",
   "metadata": {},
   "source": [
    "## Covert all video to images using ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d70587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_root = '/home/loyot/workspace/Datasets/NeRF/3d_vedio_datasets/'\n",
    "scenes = ['coffee_martini', 'cook_spinach', 'cut_roasted_beef', 'flame_salmon_1', 'flame_steak', 'sear_steak']\n",
    "ori_res = (2028, 2704)\n",
    "dst_res = (int(2704/2), int(2028/2))\n",
    "\n",
    "def exc_fn(video_list):\n",
    "    for video_path in video_list:\n",
    "        print(\"start processing video:\", video_path)\n",
    "        out, _ = (\n",
    "            ffmpeg\n",
    "            .input(video_path)\n",
    "            .output('pipe:', format='rawvideo', pix_fmt='rgb24', loglevel=\"quiet\")\n",
    "            .global_args('-hide_banner')\n",
    "            .run(capture_stdout=True)\n",
    "        )\n",
    "\n",
    "        video = (\n",
    "            np\n",
    "            .frombuffer(out, np.uint8)\n",
    "            .reshape([-1, 2028, 2704, 3])\n",
    "        )\n",
    "\n",
    "        basename = os.path.basename(video_path).split('.')[0]\n",
    "        root = os.path.join(data_path, f\"images/{basename}\")\n",
    "        os.makedirs(root, exist_ok=True)\n",
    "        print(\"start saving images\")\n",
    "        for idx in tqdm.tqdm(range(video.shape[0])):\n",
    "            img0 = Image.fromarray(video[idx]).resize(dst_res)\n",
    "            img0.save(os.path.join(data_path, root, f'{idx}.png'))\n",
    "\n",
    "        del out\n",
    "        del video\n",
    "\n",
    "p_list = []\n",
    "for scene in scenes:\n",
    "    data_path = os.path.join(data_path_root, scene)\n",
    "    video_list = glob.glob(os.path.join(data_path, '*.mp4'))\n",
    "    # exc_fn(video_list)\n",
    "    p = Process(target=exc_fn, args=(video_list,))\n",
    "    p_list.append(p)\n",
    "    p.start()\n",
    "\n",
    "for p in p_list:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b02f39-3d1f-4497-bb06-c577d00348c6",
   "metadata": {},
   "source": [
    "## HyberNeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c885909-f134-470c-b906-91cf2a52a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.datasets.hypernerf import Load_hyper_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2986f022-70c5-4c26-8c62-29480bd7c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/loyot/workspace/Datasets/NeRF/HyberNeRF/vrig_broom/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58bb28d9-b976-48fa-aaf8-a8456ab2e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f36c15eb-8cbc-486c-82fb-8b73f25f92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = glob.glob(\"/home/loyot/workspace/Datasets/NeRF/HyberNeRF/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc66586b-4d56-429a-8152-998cee600b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [da.split('/')[-1] for da in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14a107c4-0487-4810-813b-c8577ad88b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interp_aleks-teapot',\n",
       " 'interp_chickchicken',\n",
       " 'interp_cut-lemon',\n",
       " 'interp_hand',\n",
       " 'interp_slice-banana',\n",
       " 'interp_torchocolate',\n",
       " 'misc_americano',\n",
       " 'misc_cross-hands',\n",
       " 'misc_espresso',\n",
       " 'misc_keyboard',\n",
       " 'misc_oven-mitts',\n",
       " 'misc_split-cookie',\n",
       " 'misc_tamping',\n",
       " 'vrig_3dprinter',\n",
       " 'vrig_broom',\n",
       " 'vrig_chicken',\n",
       " 'vrig_peel-banana',\n",
       " 'zip_files']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c8a4d0f-519b-4e04-9225-480c9209fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.i_train [0, 3, 4, 7, 8, 11, 12, 15, 16, 19, 20, 23, 24, 27, 28, 31, 32, 35, 36, 39, 40, 43, 44, 47, 48, 51, 52, 55, 56, 59, 60, 63, 64, 67, 68, 71, 72, 75, 76, 79, 80, 83, 84, 87, 88, 91, 92, 95, 96, 99, 100, 103, 104, 107, 108, 111, 112, 115, 116, 119, 120, 123, 124, 127, 128, 131, 132, 135, 136, 139, 140, 143, 144, 147, 148, 151, 152, 155, 156, 159, 160, 163, 164, 167, 168, 171, 172, 175, 176, 179, 180, 183, 184, 187, 188, 191, 192, 195, 196, 199, 200, 203, 204, 207, 208, 211, 212, 215, 216, 219, 220, 223, 224, 227, 228, 231, 232, 235, 236, 239, 240, 243, 244, 247, 248, 251, 252, 255, 256, 259, 260, 263, 264, 267, 268, 271, 272, 275, 276, 279, 280, 283, 284, 287, 288, 291, 292, 295, 296, 299, 300, 303, 304, 307, 308, 311, 312, 315, 316, 319, 320, 323, 324, 327, 328, 331, 332, 335, 336, 339, 340, 343, 344, 347, 348, 351, 352, 355, 356, 359, 360, 363, 364, 367, 368, 371, 372, 375, 376, 379, 380, 383, 384, 387, 388, 391, 392]\n",
      "self.i_test [1, 2, 5, 6, 9, 10, 13, 14, 17, 18, 21, 22, 25, 26, 29, 30, 33, 34, 37, 38, 41, 42, 45, 46, 49, 50, 53, 54, 57, 58, 61, 62, 65, 66, 69, 70, 73, 74, 77, 78, 81, 82, 85, 86, 89, 90, 93, 94, 97, 98, 101, 102, 105, 106, 109, 110, 113, 114, 117, 118, 121, 122, 125, 126, 129, 130, 133, 134, 137, 138, 141, 142, 145, 146, 149, 150, 153, 154, 157, 158, 161, 162, 165, 166, 169, 170, 173, 174, 177, 178, 181, 182, 185, 186, 189, 190, 193, 194, 197, 198, 201, 202, 205, 206, 209, 210, 213, 214, 217, 218, 221, 222, 225, 226, 229, 230, 233, 234, 237, 238, 241, 242, 245, 246, 249, 250, 253, 254, 257, 258, 261, 262, 265, 266, 269, 270, 273, 274, 277, 278, 281, 282, 285, 286, 289, 290, 293, 294, 297, 298, 301, 302, 305, 306, 309, 310, 313, 314, 317, 318, 321, 322, 325, 326, 329, 330, 333, 334, 337, 338, 341, 342, 345, 346, 349, 350, 353, 354, 357, 358, 361, 362, 365, 366, 369, 370, 373, 374, 377, 378, 381, 382, 385, 386, 389, 390, 393]\n",
      "total 394 images  use cam = True use bg_point= False\n"
     ]
    }
   ],
   "source": [
    "hyper_data = Load_hyper_data(datadir=root+'broom', add_cam=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa9d234-40bf-4f2b-af99-6ea2271e56c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9971445 , -0.07056575,  0.02689415],\n",
       "       [ 0.07406207,  0.9833857 , -0.16573292],\n",
       "       [-0.01475226,  0.16725151,  0.9858039 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([hyper_data.all_cam_params[0].orientation, hyper_data.all_cam_params[0].position[:, None]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85ba1ca-3cc5-41b3-8c58-6a7d2c65d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00865268, -0.00921293, -0.70470877])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.all_cam_params[0].position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a030efbe-e561-4f55-999e-c6ffefd2cd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99714452, -0.07056575,  0.02689415,  0.00865268],\n",
       "       [ 0.07406207,  0.98338568, -0.16573292, -0.00921293],\n",
       "       [-0.01475226,  0.16725151,  0.9858039 , -0.70470877]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([hyper_data.all_cam_params[0].orientation, hyper_data.all_cam_params[0].position[:, None]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e459337-48b8-4a36-8b9e-3d1a3e7153dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhyper_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_cam_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhyper_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi_test\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "hyper_data.all_cam_params[hyper_data.i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a4bce-f62e-46c2-a01f-19c7357365fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hyper_data.i_test:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17f3f69e-6c6e-4d3d-a29e-c03e0e9e2963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00263565, -0.00133319], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.all_cam_params[5].tangential_distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1db5d20-7277-4136-8a73-d5a206e37587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07964308, -0.15445076,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.all_cam_params[5].radial_distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "83590823-15e2-42da-8a62-a63dff634b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_data.all_cam_params[5].principal_point_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0458d4c8-fc53-4f78-90ef-fb495e6828c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([hyper_data.all_cam_params[5].radial_distortion, hyper_data.all_cam_params[5].tangential_distortion]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8429a599-69db-404e-9646-c7a87c40bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.eye(3)[None, ...].repeat(10, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "416e1634-c427-41d0-a6f4-13d00b3f28d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 1, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3e5e07a9-73d5-40b5-9a65-5c6a86c2999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f04b9098-9dc0-47a1-97a6-42ac3dce2ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6086fcd1-e295-4c2b-a797-8e2f7ebde1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16384 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a2251-f143-4bea-81e3-c11bad1d59a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nerfacc]",
   "language": "python",
   "name": "conda-env-nerfacc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdc5c2d0e21a510627c7c0e521ac3deb474e2ecde23607639b19b4bb9e82177e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
